# -*- coding: utf-8 -*-
"""HOUSE PRICE PREDICTION

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C3L8ceVnfFNWRCarMxvDc5IbsYw1Dnlx
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Uploading the dataset


from google.colab import files

uploaded = files.upload()

df = pd.read_csv('housing.csv')
df

df.shape

"""## **Data Information & Visualisation**"""

df.head(10)

obj = (df.dtypes == 'object')
object_cols = list(obj[obj].index)
print("Categorical variables:",len(object_cols))
int_ = (df.dtypes == 'int')
num_cols = list(int_[int_].index)
print("Integer variables:",len(num_cols))
fl = (df.dtypes == 'float')
fl_cols = list(fl[fl].index)
print("Float variables:",len(fl_cols))

plt.figure(figsize=(12, 6))
sns.heatmap(df.corr(),
 cmap = 'BrBG',
 fmt = '.2f',linewidths = 2,
 annot = True)

unique_values = []
for col in object_cols:
 unique_values.append(df[col].unique().size)
plt.figure(figsize=(10,6))
plt.title('No. Unique values of Categorical Features')
plt.xticks(rotation=90)
sns.barplot(x=object_cols,y=unique_values)

plt.figure(figsize=(18, 36))
plt.title('Categorical Features: Distribution')
plt.xticks(rotation=90)
index = 1
for col in object_cols:
 y = df[col].value_counts()
 plt.subplot(11, 4, index)
 plt.xticks(rotation=90)
 sns.barplot(x=list(y.index), y=y)
 index += 1

df['median_house_value'] = df['median_house_value'].fillna(
 df['median_house_value'].mean())

new_df = df.dropna()

new_df.isnull().sum()

from sklearn.preprocessing import OneHotEncoder
s = (new_df.dtypes == 'object')
object_cols = list(s[s].index)
print("Categorical variables:")
print(object_cols)
print('No. of. categorical features: ',
 len(object_cols))

OH_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')
OH_cols = pd.DataFrame(OH_encoder.fit_transform(new_df[object_cols]))
OH_cols.index = new_df.index
OH_cols.columns = OH_encoder.get_feature_names_out()
df_final = new_df.drop(object_cols, axis=1)
df_final = pd.concat([df_final, OH_cols], axis=1)

df_final

from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
X = df_final.drop(['median_house_value'], axis=1)
Y = df_final['median_house_value']
# Split the training set into
# training and validation set
X_train, X_valid, Y_train, Y_valid = train_test_split(
 X, Y, train_size=0.8, test_size=0.2, random_state=0)

from sklearn import svm
from sklearn.svm import SVC
from sklearn.metrics import mean_absolute_percentage_error

model_SVR = svm.SVR()
model_SVR.fit(X_train,Y_train)
Y_pred = model_SVR.predict(X_valid)
print(mean_absolute_percentage_error(Y_valid, Y_pred))